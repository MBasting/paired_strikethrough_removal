# Paired Image to Image Translation for Strikethrough Removal From Handwritten Words Further Work
This project was done by Alexander, Sven and Mark for the Computer Vision for Deep Learning course

[![License](https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square)](https://opensource.org/licenses/MIT) [![DOI](https://zenodo.org/badge/471974467.svg)](https://zenodo.org/badge/latestdoi/471974467)


### Original Authors: [Raphaela Heil](mailto:raphaela.heil@it.uu.se):envelope:, [Ekta Vats](ekta.vats@it.uu.se) and [Anders Hast](anders.hast@it.uu.se)


## Table of Contents
1. [Code](#code)
    1. [Train](#train)
    2. [Test](#test)
2. [Data](#data)
3. [Citation](#citation)
4. [Acknowledgements](#acknowledgements)


## 1 Code

Warning: This code is especially written for linux-based machines as it depends on the Octopytorch library which supports, to our knowledge, only linux-based machines. 

Requirements necessary, such as octopytorch, can be found in `requirements.txt` and `requirements_strik_rem.txt` which contains the necessary packages and libraries necessary to train the CycleGAN. 

### 1.1 Train 
For all models except the CycleGAN run and Vision Transformer
```bash
python -m src.train -file <path to config file> -section <section name>
```
By default, the path to the config file will be to `config_files/config.cfg` and the standard section will be `DEFAULT`.

For CycleGAN:
```bash
python -m src.cycle_gan.train_gan -configfile <path to config file> -config <section name>
```
The config file used to train CycleGAN is `config_files\serverConfig_strike_rem.cfg`. 

Methods for evaluating multiple datasets and models can be found in ```src/train.py```

For Vision Transformer:
A jupyter notebook with the code necessary to train the vision transformer can be found in `transformer\notebooks\strikethrough.ipynb`. 

### 1.2 Test
```bash
python -m src.test -file <path to config file> -data <path to test data>
```

If you want to use a checkpoint with a different name than `best_fmeasure.pth` add: `-checkpoint <filename>` and if you want to save the model outputs, i.e. cleaned images, add the flag `-save`

### 1.3 Visualize Results Boxplot
This repository also contains a python script which makes it possible to visualize the results in a boxplot from generated json files. These json files are generated when the `evaluate_file` or `evaluate_folder` methods are called in `src\test.py`. 

```bash
python -m src.visualize -result <path to json file containing results>
```
### 1.4 Visualize intermediate losses and results
```bash
tensorboard --logdir <path to specific run in runs folder>
```

A video of the intermediate results can be generated by running: 
``` bash
python src/create_Video.py -folder <path to folder containing results for 1 setup>
```

## Data
- IAM<sub>synth</sub>: Synthetic strikethrough dataset
    - Zenodo: [https://doi.org/10.5281/zenodo.4767094](https://doi.org/10.5281/zenodo.4767094)
    - based on the [IAM](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database) database
    - multi-writer
    - generated using [https://doi.org/10.5281/zenodo.4767062](https://doi.org/10.5281/zenodo.4767062)
- IAM<sub>synth</sub>: Synthetic strikethrough dataset
    - Zenodo: [https://doi.org/10.5281/zenodo.4767094](https://doi.org/10.5281/zenodo.4767094)
    - based on the [IAM](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database) database
    - multi-writer
    - Generated using [https://doi.org/10.5281/zenodo.4767062](https://doi.org/10.5281/zenodo.4767062)
    - Generated all possible strikethroughs for each word instead of for a selection of writers and randomly sampled strikethroughs
- Dracula<sub>real</sub>: Genuine strikethrough dataset
    - Zenodo: [https://doi.org/10.5281/zenodo.4765062](https://doi.org/10.5281/zenodo.4765062)
    - single-writer
    - blue ballpoint pen
    - clean and struck word images registered based on:
        >J. Öfverstedt, J. Lindblad and N. Sladoje, "Fast and Robust Symmetric Image Registration Based on Distances Combining Intensity and Spatial Information," in IEEE Transactions on Image Processing, vol. 28, no. 7, pp. 3584-3597, July 2019, doi: 10.1109/TIP.2019.2899947.
    ([Paper](https://ieeexplore.ieee.org/document/8643403), [Code](https://github.com/MIDA-group/py_alpha_amd_release))
- Dracula<sub>synth</sub>: Synthetic single-write dataset
    - Zenodo: [https://doi.org/10.5281/zenodo.6406538](https://doi.org/10.5281/zenodo.6406538)  
    - based on the train split of Dracula<sub>real</sub>
    - five partitions with different strikethrough strokes applied to each word

The standard folderstructure that is already configured is:
```├── datasets
│   ├── Dracula_real
│   │   ├── test
│   │   │   ├── struck
│   │   │   └── struck_gt
│   │   ├── train
│   │   │   ├── clean
│   │   │   ├── struck
│   │   │   └── struck_gt
│   │   └── validation
│   │       ├── struck
│   │       └── struck_gt
│   ├── Dracula_synth
│   │   └── train
│   │       ├── fold_0
│   │       ├── fold_1
│   │       ├── fold_2
│   │       ├── fold_3
│   │       └── fold_4
│   ├── IAMsynth_full
│   │   ├── test
│   │   │   ├── clean
│   │   │   ├── struck
│   │   │   └── struck_gt
│   │   ├── train
│   │   │   ├── clean
│   │   │   ├── struck
│   │   │   └── struck_gt
│   │   └── validation
│   │       ├── clean
│   │       ├── struck
│   │       └── struck_gt
│   ├── IAMsynth_all
│   │   ├── gt
│   │   ├── test
│   │   │   ├── struck
│   │   ├── train
│   │   │   ├── struck
│   │   └── validation
│   │   │   ├── struck
```
This folder-structure can easily be followed by downloading the datasets linked above, configuring them if necessary and copying them in a folder called `datasets`. 

## 3 Citation
[DAS 2022](https://das2022.univ-lr.fr/)

```
@INPROCEEDINGS{heil2022strikethrough,
  author={Heil, Raphaela and Vats, Ekta and Hast, Anders},
  booktitle={15TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2022)},
  title={{Paired Image to Image Translation for Strikethrough Removal From Handwritten Words}},
  year={2022},
  pubstate={to appear}}
```
ICDAR 2021

```
@INPROCEEDINGS{heil2021strikethrough,
  author={Heil, Raphaela and Vats, Ekta and Hast, Anders},
  booktitle={2021 International Conference on Document Analysis and Recognition (ICDAR)},
  title={{Strikethrough Removal from Handwritten Words Using CycleGANs}},
  year={2021},
  pubstate={to appear}}
```
```
@article{gunducc2021tensor,
  title={Tensor-to-Image: Image-to-Image Translation with Vision Transformers},
  author={G{\"u}nd{\"u}{\c{c}}, Yi{\u{g}}it},
  journal={arXiv preprint arXiv:2110.08037},
  year={2021}
}
```


## 4 Acknowledgements 
This work is a continuation on the work done by the above authors and much credits goes to their work and original codebase which can be found [here](https://github.com/RaphaelaHeil/paired_strikethrough_removal). The CycleGAN code also mentioned in the paper during evaluation can also be found in this repository, which original can be found [here](https://github.com/RaphaelaHeil/strikethrough-removal-cyclegans/tree/main) 
