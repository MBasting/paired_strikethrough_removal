{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHaQkNvlc1ki",
    "outputId": "23afd6fb-521c-4b67-d765-22812a8a5bab",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMZaGHOlc0SD",
    "outputId": "9f0ad718-d88a-4384-a315-fc8be1109a3e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = './../../datasets/ours'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "8Mx-LXgLc0SM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../../datasets/ours/struck/h07-023-07-04_StrokeType.DOUBLE_LINE.png ./../../datasets/ours/clean/b06-075-08-01.png\n"
     ]
    }
   ],
   "source": [
    "input_paths = glob.glob(dataset_path + '/struck/*.png')\n",
    "target_paths = glob.glob(dataset_path + '/clean/*.png')\n",
    "print(input_paths[0], target_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "4OVZgPjtc0SP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400\n",
    "EPOCHS = 100\n",
    "LAMBDA = 100\n",
    "BATCH_SIZE = 8\n",
    "IMG_WIDTH = 600\n",
    "IMG_HEIGHT = 600\n",
    "patch_size = 8\n",
    "num_patches = (IMG_HEIGHT // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "embed_dim = 64\n",
    "num_heads = 2 \n",
    "ff_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "AvaXbs4lc0SR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load(path):\n",
    "\n",
    "    v = path.split(\"/\")[-1].split(\"_\", 1)\n",
    "    name, strikethrough_type = v[0], v[1]\n",
    "    \n",
    "    input_path = path\n",
    "    target_path = dataset_path + '/clean/' + name + '.png'\n",
    "\n",
    "\n",
    "    input_image = tf.io.read_file(input_path)\n",
    "    input_image = tf.image.decode_png(input_image)\n",
    "    \n",
    "    target_image = tf.io.read_file(target_path)\n",
    "    target_image = tf.image.decode_png(target_image)\n",
    "    \n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    target_image = tf.cast(target_image, tf.float32)\n",
    "\n",
    "\n",
    "    return tf.image.grayscale_to_rgb(input_image), tf.image.grayscale_to_rgb(target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "y8_ilo0Fc0SS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "opCaZjvRc0ST",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(input_image, target_image):\n",
    "    input_image = input_image / 255\n",
    "    target_image = target_image / 255\n",
    "\n",
    "    return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "bvQKHD3-c0SU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_image_train(depth_path):\n",
    "    input_image, target = load(depth_path)\n",
    "    if input_image.shape[0] > 600:\n",
    "        return None\n",
    "    if input_image.shape[1] > 350:\n",
    "        return None\n",
    "    input_image, target = resize(input_image, target,\n",
    "                                   IMG_HEIGHT, IMG_WIDTH)\n",
    "    input_image, target = normalize(input_image, target)\n",
    "\n",
    "    return input_image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "def load_data_generator(input_paths):\n",
    "    for input_path in input_paths:\n",
    "        v = load_image_train(input_path)\n",
    "        if v is None:\n",
    "            continue\n",
    "\n",
    "        yield v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "hm6uhABxc0SW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "VqAxP9ayc0SX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"SAME\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "n_mdkF59c0SX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PatchEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "ZNDm9KXXc0SY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "RPZFwD5PP4af",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "lcQVzKBDc0SZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def Generator():\n",
    "\n",
    "    inputs = layers.Input(shape=(600, 600, 3))\n",
    "\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    x = TransformerBlock(64, num_heads, ff_dim)(encoded_patches)\n",
    "    x = TransformerBlock(64, num_heads, ff_dim)(x)\n",
    "    x = TransformerBlock(64, num_heads, ff_dim)(x)\n",
    "    x = TransformerBlock(64, num_heads, ff_dim)(x)\n",
    "    x = layers.Reshape((8, 8, 5625))(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = residual_block(x, downsample=False, filters=512)\n",
    "\n",
    "    x = layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = residual_block(x, downsample=False, filters=256)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = residual_block(x, downsample=False, filters=64)\n",
    "\n",
    "    x = layers.Conv2DTranspose(32, (5, 5), strides=(4, 4), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = residual_block(x, downsample=False, filters=32)\n",
    "\n",
    "    x = layers.Conv2D(1, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh')(x)\n",
    "    print(inputs)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DBHxlKHvc0Sa",
    "outputId": "0b70c08f-2c2c-4d01-dd44-e340c0b088c0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 600, 600, 3), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\")\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 600, 600, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " patches_10 (Patches)           (None, None, 192)    0           ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " patch_encoder_10 (PatchEncoder  (None, 5625, 64)    372352      ['patches_10[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " transformer_block_40 (Transfor  (None, 5625, 64)    37664       ['patch_encoder_10[0][0]']       \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_41 (Transfor  (None, 5625, 64)    37664       ['transformer_block_40[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_42 (Transfor  (None, 5625, 64)    37664       ['transformer_block_41[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " transformer_block_43 (Transfor  (None, 5625, 64)    37664       ['transformer_block_42[0][0]']   \n",
      " merBlock)                                                                                        \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)           (None, 8, 8, 5625)   0           ['transformer_block_43[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_transpose_40 (Conv2DTra  (None, 16, 16, 512)  72000000   ['reshape_10[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 16, 16, 512)  2048       ['conv2d_transpose_40[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_40 (LeakyReLU)     (None, 16, 16, 512)  0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 16, 16, 512)  2359808     ['leaky_re_lu_40[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_80 (ReLU)                (None, 16, 16, 512)  0           ['conv2d_90[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 16, 16, 512)  2048       ['re_lu_80[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 16, 16, 512)  2359808     ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 16, 16, 512)  0           ['leaky_re_lu_40[0][0]',         \n",
      "                                                                  'conv2d_91[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_81 (ReLU)                (None, 16, 16, 512)  0           ['add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 16, 16, 512)  2048       ['re_lu_81[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_41 (Conv2DTra  (None, 32, 32, 256)  3276800    ['batch_normalization_122[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 32, 32, 256)  1024       ['conv2d_transpose_41[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_41 (LeakyReLU)     (None, 32, 32, 256)  0           ['batch_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 32, 32, 256)  590080      ['leaky_re_lu_41[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_82 (ReLU)                (None, 32, 32, 256)  0           ['conv2d_92[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 32, 32, 256)  1024       ['re_lu_82[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 32, 32, 256)  590080      ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 32, 32, 256)  0           ['leaky_re_lu_41[0][0]',         \n",
      "                                                                  'conv2d_93[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_83 (ReLU)                (None, 32, 32, 256)  0           ['add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 32, 32, 256)  1024       ['re_lu_83[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_42 (Conv2DTra  (None, 64, 64, 64)  409600      ['batch_normalization_125[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 64, 64, 64)  256         ['conv2d_transpose_42[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_42 (LeakyReLU)     (None, 64, 64, 64)   0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 64, 64, 64)   36928       ['leaky_re_lu_42[0][0]']         \n",
      "                                                                                                  \n",
      " re_lu_84 (ReLU)                (None, 64, 64, 64)   0           ['conv2d_94[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 64, 64, 64)  256         ['re_lu_84[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 64, 64, 64)   36928       ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 64, 64, 64)   0           ['leaky_re_lu_42[0][0]',         \n",
      "                                                                  'conv2d_95[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_85 (ReLU)                (None, 64, 64, 64)   0           ['add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 64, 64, 64)  256         ['re_lu_85[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_43 (Conv2DTra  (None, 256, 256, 32  51200      ['batch_normalization_128[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 256, 256, 32  128        ['conv2d_transpose_43[0][0]']    \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_43 (LeakyReLU)     (None, 256, 256, 32  0           ['batch_normalization_129[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 256, 256, 32  9248        ['leaky_re_lu_43[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_86 (ReLU)                (None, 256, 256, 32  0           ['conv2d_96[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 256, 256, 32  128        ['re_lu_86[0][0]']               \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 256, 256, 32  9248        ['batch_normalization_130[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 256, 256, 32  0           ['leaky_re_lu_43[0][0]',         \n",
      "                                )                                 'conv2d_97[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_87 (ReLU)                (None, 256, 256, 32  0           ['add_43[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 256, 256, 32  128        ['re_lu_87[0][0]']               \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 256, 256, 1)  288         ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82,263,392\n",
      "Trainable params: 82,258,208\n",
      "Non-trainable params: 5,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n",
    "generator.summary()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "lw8T5T3Ac0Sd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "Gl9RqSOHc0Se",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    display_list = [test_input[0], np.array(tar[0]).reshape(256, 256), np.array(prediction[0]).reshape(256, 256)]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def generate_batch_images(model, test_input, tar):\n",
    "    for i in range(len(test_input)):\n",
    "        prediction = model(test_input, training=True)\n",
    "        plt.figure(figsize=(15, 15))\n",
    "\n",
    "        display_list = [test_input[i], tar[i], prediction[i]]\n",
    "        title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            plt.title(title[i])\n",
    "            # getting the pixel values between [0, 1] to plot it.\n",
    "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "N2M-Jbjvc0Se",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            gen_output = generator(input_image, training=True)\n",
    "            gen_total_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "        \n",
    "\n",
    "        generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                              generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                              generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "5wOgyEJmc0Se",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "        # Train\n",
    "        for n, v in train_ds.enumerate():\n",
    "            struck, clean = np.swapaxes(v, 0, 1)\n",
    "            print('.', end='')\n",
    "            if (n+1) % 100 == 0:\n",
    "                print()\n",
    "            train_step(struck, clean)\n",
    "        print()\n",
    "\n",
    "        generator.save_weights(f'strikethrough.ipynb-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "z4Kq8t1kc0Se",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: load_data_generator(input_paths), output_shapes=(2, 600, 600, 3), output_types=(tf.float32))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1SXMOPoc0Se",
    "outputId": "ee25b332-c08f-4ec4-eb15-1d59a4e896b2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 23:28:47.600067: W tensorflow/core/framework/op_kernel.cc:1733] UNKNOWN: JIT compilation failed.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "JIT compilation failed. [Op:FloorMod]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [256]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [254]\u001B[0m, in \u001B[0;36mfit\u001B[0;34m(train_ds, epochs)\u001B[0m\n\u001B[1;32m     11\u001B[0m struck, clean \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mswapaxes(v, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m()\n\u001B[1;32m     15\u001B[0m train_step(struck, clean)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7164\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   7162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[1;32m   7163\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 7164\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[0;31mUnknownError\u001B[0m: JIT compilation failed. [Op:FloorMod]"
     ]
    }
   ],
   "source": [
    "fit(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6H20taNNc0Sf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generator.save_weights('gen-depth-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9mSLHL9Ac0Sf",
    "outputId": "44e8b2a6-eec6-4041-c7f9-87da233911ba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for example_input, example_target in train_dataset.take(54):\n",
    "    generate_images(generator, example_input, example_target)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "image2image_depth-res.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}